# Music Recommender System using Russel's Circumplex Model

## Introduction
This senior project focuses on developing a music recommendation system built on a Two-Tower Model architecture that leverages song mood prediction. By employing machine learning techniques like Support Vector Machines, Random Forest, and XGBoost, the project aims to accurately classify musics into emotional quadrants based on audio features and lyrics.

## Datasets Used

### 1. Music Emotion Data
#### 1.1 Aljanaki, A., Yang, Y.-H., & Soleymani, M. (2017). *DEAM: MediaEval Database for Emotional Analysis in Music.*  
Dataset available at [https://multimediaeval.github.io/](https://multimediaeval.github.io/)

#### 1.2 Stappen, L., Baird, A., & Schuller, B. W. (2021). *The MuSe 2021 multimodal sentiment analysis challenge: Sentiment, emotion, physiological-emotion, and stress.*  
Proceedings of the ACM International Conference on Multimedia (MM), 2021. Dataset available at [https://www.muse-challenge.org/](https://www.muse-challenge.org/)

#### 1.3 Zhang, Y., Jin, Z., Zhao, M., Chen, F., & Guan, X. (2018). *PMEmo: A music dataset for valence-arousal emotion recognition.*  
Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2018. Dataset available at [https://github.com/HuiZhangDB/PMEmo](https://github.com/HuiZhangDB/PMEmo)

### 2. User Data and Music Data for Recommender System
#### 2.1 Bertin-Mahieux, T., Ellis, D. P. W., Whitman, B., & Lamere, P. (2011). *The Million Song Dataset.*  
Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2011. Dataset available at [http://millionsongdataset.com/](http://millionsongdataset.com/)
