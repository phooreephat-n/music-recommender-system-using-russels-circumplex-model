{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e75d7370272047418a0526420060ffa6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6326,
    "execution_start": 1724126519013,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unidecode\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993241 sha256=91b369d402a62171e74dab0a2b325ab9113b5bd564061a7965f0004c1b7f29f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: unidecode, langdetect\n",
      "Successfully installed langdetect-1.0.9 unidecode-1.3.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "126ab5e58b4343499a204eceadfbdf75",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4417,
    "execution_start": 1724127535669,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /root/venv/lib/python3.9/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e7bf09340ff54ce98b548346f5ec21d6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 132,
    "execution_start": 1724127544585,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Import NLTK\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download the necessary NLTK resources (only need to do this once)\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import unidecode\n",
    "\n",
    "# Import LangDetect\n",
    "from langdetect import detect, DetectorFactory\n",
    "# Ensure consistent results from langdetect\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f7966b41a0514eaf9eb0b4eb7281beab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 52,
    "execution_start": 1724127895970,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Function to detect languages\n",
    "def detect_languages(text):\n",
    "    try:\n",
    "        languages = detect_langs(text)\n",
    "        return str(languages)\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Function to check if 'en' has a probability greater than 0.5\n",
    "def has_high_en_prob(lang_str):\n",
    "    if lang_str == 'Unknown':\n",
    "        return False\n",
    "    for lang in lang_str.split(','):\n",
    "        lang = lang.strip('[] ')\n",
    "        if lang.startswith('en'):\n",
    "            prob = float(lang.split(':')[1])\n",
    "            if prob > 0.5:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f47d135822cc4b1bb46353f00faa194e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 89,
    "execution_start": 1724127737322,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Helper function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "def clean_and_lemmatize_lyrics(lyrics):\n",
    "    \"\"\"\n",
    "    Cleans and lemmatizes song lyrics by removing unwanted text, normalizing, and lemmatizing words.\n",
    "\n",
    "    Args:\n",
    "    - lyrics (str): The lyrics to be cleaned and lemmatized.\n",
    "\n",
    "    Returns:\n",
    "    - str: The cleaned and lemmatized lyrics.\n",
    "    \"\"\"\n",
    "    # Step 1: Remove unwanted phrases, section titles, and punctuation\n",
    "    cleaned_lyrics = re.sub(r\"\\d+\\sContributors.*?Lyrics\", \"\", lyrics, flags=re.DOTALL)\n",
    "    cleaned_lyrics = re.sub(r\"See .*?Get tickets.*?\\$\\d+\", \"\", cleaned_lyrics, flags=re.DOTALL)\n",
    "    cleaned_lyrics = re.sub(r\"Embed|\\(.*?\\)|\\[.*?\\]|\\d+|[\\\",\\'\\-?!.]\", \"\", cleaned_lyrics)\n",
    "    cleaned_lyrics = re.sub(r'_+\\s*', '', cleaned_lyrics)\n",
    "    \n",
    "    # Step 2: Normalize text by removing special patterns and non-alphabet characters\n",
    "    cleaned_lyrics = re.sub(r'\\s+', ' ', cleaned_lyrics.replace(\"\\n\", \" \")).strip()\n",
    "    cleaned_lyrics = unidecode.unidecode(cleaned_lyrics.lower())\n",
    "\n",
    "    # Step 3: Lemmatize the cleaned lyrics\n",
    "    tokens = word_tokenize(cleaned_lyrics)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(tag))\n",
    "        for token, tag in tagged_tokens\n",
    "    ]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Transforms text with special fonts into normal fonts.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    - str: The normalized text.\n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r'(a{2,}|h{2,})+', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', cleaned_text)\n",
    "    return unidecode.unidecode(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "60f0a4b96f7b4c44818aef59bbfb924e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 741,
    "execution_start": 1724127739879,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "song_df_with_lyrics = pd.read_csv(\"/song_df_with_lyrics.csv\")\n",
    "song_df_with_lyrics = song_df_with_lyrics.dropna(subset=[\"lyrics\"]).reset_index(drop=True)\n",
    "song_df_with_lyrics = song_df_with_lyrics[['spotify_id', 'lyrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6fa7d1d816de483abe3d7dba4afb2b94",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 36574,
    "execution_start": 1724127906729,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Apply the function to the column and create a new column\n",
    "song_df_with_lyrics['detected_languages'] = song_df_with_lyrics['lyrics'].apply(detect_languages)\n",
    "\n",
    "# Filter rows where 'en' has a probability > 0.5\n",
    "song_df_with_lyrics = song_df_with_lyrics[song_df_with_lyrics['detected_languages'].apply(has_high_en_prob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_and_lemmatize_lyrics function to the \"lyrics\" column\n",
    "song_df_with_lyrics['cleaned_lyrics'] = song_df_with_lyrics['lyrics'].apply(clean_and_lemmatize_lyrics)\n",
    "\n",
    "song_df_with_lyrics['normalized_lyrics'] = song_df_with_lyrics['cleaned_lyrics'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "588e458641d74333afb3bd791bf60cf0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 37,
    "execution_start": 1724128426409,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "song_df_with_lyrics = song_df_with_lyrics['normalized_lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0527999588af48dc903e3a8568d01fb5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 295,
    "execution_start": 1724128450473,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a day in falsettoland dr mendel at work you go out on the street and theres all these people ask for a handout you go home you open your mail and it full of people ask for a donation i dont get it then you turn on the tv and they want money for i dont understand starve child in ethiopia i just want to be leave alone in the s everyone have heart in the s we be all a part of the same team in the s we have a new world to start could this oh god dont say it is could this be the new world we start here i sit brokenhearted and do i wait for the promotion or do i take this ibm job yeah well caroline hmm i dont get it ive be leave behind half my patient  yuppie pagan model on the ronald reagans now the world be too pathetic and i dont get it at all oh im in a deep quandary about my career what do you think i should do time up aww at least there trina at home trina in bed trina obsessing and sort of caress my head with her foot i once think it be sweet but i dont anymore now i just snore cause im so exhausted listening a those yuppie fart complain listening a their shallow heart explain their life trina work it out marvins back with whizzer just like how it be if i dont like whizzer it because my ex sure do why should that affect me sometimes im a lout mendel serenade and jason calm me why should i be wilt when their precious love be not in doubt work it out the neighbor relax how be your day at the hospital unbelievable what be that smell nouvelle bar mitzvah cuisine ive be practice cuisine bar mitzvah nouvelle well hi honey hi honey how be your day it be terrible do you hear that marvins back with whizzer marvins back with whizzer drop it sweetheart give it up you know i love you honey sweetheart whats the matter i dont get it why dont you let go after the first mile ill be okay i can not let go until we have this bar mitzvah isnt it enough i want you every night huh every other night huh huh huh huh huh every third night everything will be alright everything will be alright everything will be alright how be your day at the hospital it be wonderful for the first time in month nobody die there be just heart attack and gallstone light bulbs up the as fake appendicitis which be gas which i diagnosed people overdose and i save them i save young people old people one priest and one high school principal save life i feel invincible yes i do do you know how great my life be do you know how great my life be save life and love you you save life and i save chicken fat i cant fuck deal with that do you know how great my life be yes i know how great your life be everything will be alright do you know how great my life be yes i know how great your life be everything will be alright do you know how great my life be yes i know how great your life be everything will be alright save life and love you it bounce twice no it didnt once then twice you know it do thats not nice no it isnt but youre a pain in the as youre a beast but at least when you play me you win you give up i perspire wheres the heat wheres the fire use to be youd desire a fight so fight so play onetwothreefour onetwothreefour onetwothreefour onetwothreefour lucky dink im fin something stink in how you play dont you think it a blessing im so pathetically bad just stay back serve with force ill attack and of course i will win just give in to bliss and kiss let go do you know down the alley all i want be you high lob anything low drive you do ooh be all right ceiling shot yes it all right into the court do you know four wall all i want dink be you hit your shoe no it didnt yes it do the game be through thats not nice no it isnt god youre a pain in the as play it raw dont play pretty sex and game in new york city have get to be play with flair and passion and passion and flair do you know do you know how great my life be all i want be you do you know how great my life be anything you do be alright everything will be alright yes it alright everything will be alright everything will everything will everything will be alright everything will everything will everything will be be be alright alright soup do'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df_with_lyrics[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df_with_lyrics.to_csv('/song_df_with_lyrics.csv')"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "3b66d9162fad4930857410a651506949",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
